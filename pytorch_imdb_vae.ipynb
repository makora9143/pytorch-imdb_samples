{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T08:43:33.123370",
     "start_time": "2017-06-20T17:43:31.109615+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "use_cuda = True\n",
    "device_id = 3\n",
    "from tensorflow.contrib.keras.python.keras.datasets.imdb import load_data, get_word_index\n",
    "\n",
    "max_features = 5000\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T08:44:15.482005",
     "start_time": "2017-06-20T17:43:33.979331+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T08:44:15.520291",
     "start_time": "2017-06-20T17:44:15.485515+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "\n",
    "def pad(tensor, length):\n",
    "    return torch.cat([tensor, tensor.new(length - tensor.size(0),*tensor.size()[1:]).zero_()])\n",
    "\n",
    "\n",
    "def sortedText(idx, xs, ys):\n",
    "    batch_xs = xs[idx]\n",
    "    batch_ys = ys[idx]\n",
    "    lengths = np.array([len(x) for x in batch_xs])\n",
    "    sort_idx = np.argsort(lengths)[::-1]\n",
    "    return batch_xs[sort_idx], lengths[sort_idx], batch_ys[sort_idx]\n",
    "\n",
    "\n",
    "def textTensor(idx, xs, ys):\n",
    "    batch_xs, lengths, batch_ys = sortedText(idx, xs, ys)\n",
    "    max_length = lengths[0]\n",
    "    return torch.cat([pad(torch.Tensor(x), max_length).view(max_length, 1)\n",
    "                      for x in batch_xs], 1).long(), list(lengths), torch.FloatTensor(batch_ys)\n",
    "\n",
    "\n",
    "def get_last_step_indices(lengths):\n",
    "    n_lengths = len(lengths)\n",
    "    rev_lengths = lengths[::-1]\n",
    "    rev_lengths_sum = torch.LongTensor(rev_lengths).cumsum(0)\n",
    "    return torch.LongTensor([(n_lengths - i - 1) * length + rev_lengths_sum[i] - 1\n",
    "                         for i, length in enumerate(rev_lengths)][::-1])\n",
    "\n",
    "\n",
    "def get_last_step_tensor(packed_sequence, lengths):\n",
    "    indices = Variable(torch.LongTensor(get_last_step_indices(lengths)))\n",
    "    if packed_sequence.data.data.is_cuda:\n",
    "        indices = indices.cuda(packed_sequence.data.data.get_device())\n",
    "    last_step = packed_sequence.data.index_select(0, indices)\n",
    "    return last_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T09:12:01.613498",
     "start_time": "2017-06-20T18:12:01.594337+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1):\n",
    "        super(SimpleEncoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "    \n",
    "        \n",
    "    def forward(self, word_input, input_length, hidden=None):\n",
    "        output = self.embedding(word_input)\n",
    "        output = pack_padded_sequence(output, input_length)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output, input_length = pad_packed_sequence(output)\n",
    "        \n",
    "        return output, hidden\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T09:12:06.327499",
     "start_time": "2017-06-20T18:12:05.085770+09:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -5.0188 -5.2886 -5.0984  ...  -5.0488 -4.8925 -4.8270\n",
       " -4.7947 -4.6121 -4.9453  ...  -4.8032 -4.7558 -4.8937\n",
       " -4.9578 -4.9013 -4.9274  ...  -4.6281 -4.9961 -4.7988\n",
       "           ...             ⋱             ...          \n",
       " -4.8716 -4.7846 -4.6863  ...  -4.7796 -4.6275 -4.9536\n",
       " -4.8436 -4.8571 -5.0308  ...  -4.8387 -4.8874 -4.6102\n",
       " -5.1017 -4.6260 -4.4362  ...  -4.9277 -4.8420 -4.6734\n",
       " [torch.FloatTensor of size 32x128], (Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -0.1453 -0.4150 -0.2249  ...  -0.1753 -0.0190  0.0466\n",
       "    0.0786  0.2612 -0.0720  ...   0.0701  0.1175 -0.0203\n",
       "   -0.1127 -0.0562 -0.0823  ...   0.2169 -0.1510  0.0463\n",
       "             ...             ⋱             ...          \n",
       "    0.0171  0.1042  0.2024  ...   0.1092  0.2613 -0.0649\n",
       "   -0.0046 -0.0181 -0.1918  ...   0.0002 -0.0485  0.2287\n",
       "   -0.2029  0.2728  0.4626  ...  -0.0288  0.0568  0.2255\n",
       "  [torch.FloatTensor of size 1x32x128], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -0.5042 -0.6762 -0.3190  ...  -0.3945 -0.0509  0.0800\n",
       "    0.3588  0.4318 -0.2343  ...   0.1683  0.3877 -0.0343\n",
       "   -0.4266 -0.0869 -0.1948  ...   0.5287 -0.4537  0.1982\n",
       "             ...             ⋱             ...          \n",
       "    0.0798  0.2440  0.2455  ...   0.2653  0.5956 -0.1025\n",
       "   -0.0119 -0.0542 -0.3520  ...   0.0003 -0.0721  0.3967\n",
       "   -0.3881  0.3568  0.7048  ...  -0.0397  0.1017  0.8345\n",
       "  [torch.FloatTensor of size 1x32x128]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, lengths, y = textTensor(range(32), x_train, y_train)\n",
    "x, y = Variable(x), Variable(y)\n",
    "SimpleDecoder(20000, 256, 128)(x, lengths, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T09:11:58.905547",
     "start_time": "2017-06-20T18:11:58.896843+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, max_features, embedding_size, hidden_size, n_layers=1):\n",
    "        super(SimpleDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(max_features, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size, max_features)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, word_inputs, input_lengths, hidden):\n",
    "        output = self.embedding(word_inputs)\n",
    "        output = pack_padded_sequence(output, input_lengths)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.softmax(hidden[0][0])\n",
    "        return output, hidden\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-20T05:05:36.105Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    idx, y = iter(train_loader).next()\n",
    "    x, lengths, y = textTensor(idx, x_train, y_train)\n",
    "    x, y = Variable(x), Variable(y)\n",
    "    print('input_batches', x.size()) \n",
    "    model = IMDB_Classifier(max_features, 2, 32)\n",
    "    model = model.cuda() if use_cuda else model\n",
    "    (x, y) = (x.cuda(), y.cuda()) if use_cuda else (x, y)\n",
    "    output = model(x, lengths)\n",
    "    print('output_batches', output.size()) \n",
    "    cretrion = nn.BCELoss()\n",
    "\n",
    "    print(cretrion(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-20T05:05:36.109Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 10, batch_loss: 0.69545943141\n",
      "batch: 20, batch_loss: 0.691866585612\n",
      "batch: 30, batch_loss: 0.690033572912\n",
      "batch: 40, batch_loss: 0.688602542877\n",
      "batch: 50, batch_loss: 0.688659090996\n",
      "batch: 60, batch_loss: 0.687320863207\n",
      "batch: 70, batch_loss: 0.68498005867\n",
      "batch: 80, batch_loss: 0.683520531654\n",
      "batch: 90, batch_loss: 0.68325273527\n",
      "batch: 100, batch_loss: 0.679330698848\n",
      "batch: 110, batch_loss: 0.678382878412\n",
      "batch: 120, batch_loss: 0.672522056599\n",
      "batch: 130, batch_loss: 0.67177152221\n",
      "batch: 140, batch_loss: 0.667980640275\n",
      "batch: 150, batch_loss: 0.66621500055\n",
      "batch: 160, batch_loss: 0.665801773965\n",
      "batch: 170, batch_loss: 0.664297933789\n",
      "batch: 180, batch_loss: 0.662891145547\n",
      "batch: 190, batch_loss: 0.660225103717\n",
      "batch: 200, batch_loss: 0.654279608577\n",
      "batch: 210, batch_loss: 0.651508088481\n",
      "batch: 220, batch_loss: 0.649304654246\n",
      "batch: 230, batch_loss: 0.647736446106\n",
      "batch: 240, batch_loss: 0.645605652158\n",
      "batch: 250, batch_loss: 0.642742213368\n",
      "batch: 260, batch_loss: 0.641271293278\n",
      "batch: 270, batch_loss: 0.640277818839\n",
      "batch: 280, batch_loss: 0.639030138935\n",
      "batch: 290, batch_loss: 0.636933143899\n",
      "batch: 300, batch_loss: 0.635473065873\n",
      "batch: 310, batch_loss: 0.633300299125\n",
      "batch: 320, batch_loss: 0.630199204944\n",
      "batch: 330, batch_loss: 0.628416026993\n",
      "batch: 340, batch_loss: 0.626825142871\n",
      "batch: 350, batch_loss: 0.62423387519\n",
      "batch: 360, batch_loss: 0.62293313601\n",
      "batch: 370, batch_loss: 0.622251633293\n",
      "batch: 380, batch_loss: 0.621796567895\n",
      "batch: 390, batch_loss: 0.61990033113\n",
      "batch: 400, batch_loss: 0.617315956727\n",
      "batch: 410, batch_loss: 0.616538981039\n",
      "batch: 420, batch_loss: 0.61516204228\n",
      "batch: 430, batch_loss: 0.614706015448\n",
      "batch: 440, batch_loss: 0.613778257776\n",
      "batch: 450, batch_loss: 0.61277222534\n",
      "batch: 460, batch_loss: 0.611048684755\n",
      "batch: 470, batch_loss: 0.608614265919\n",
      "batch: 480, batch_loss: 0.607366821294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = IMDB_Classifier(max_features, 128, batch_size)\n",
    "clf = clf.cuda(device_id) if use_cuda else clf\n",
    "optimizer = optim.Adam(clf.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, 101):\n",
    "    losses = 0\n",
    "    indices = np.random.permutation(np.array(range(25000)))\n",
    "    for i in range(1, indices.shape[0] / 32 + 1):\n",
    "        x, lengths, y = textTensor(indices[(i-1)*32:i*32], x_train, y_train)\n",
    "        x, y = Variable(x), Variable(y)\n",
    "\n",
    "        (x, y) = (x.cuda(device_id), y.cuda(device_id)) if use_cuda else (x, y)\n",
    "\n",
    "        output = clf(x, lengths)\n",
    "        loss = criterion(output, y)\n",
    "        losses += loss.data[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"batch: {}, batch_loss: {}\".format(i, losses / i))\n",
    "\n",
    "    print(\"Epoch: {}, time: {}, loss: {}\".format(epoch, timeSince(start, float(epoch) / epochs), losses/(i)))\n",
    "\n",
    "\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(250):\n",
    "        x, lengths, y = textTensor(range(25000)[i*100:(i+1)*100], x_train, y_train)\n",
    "        #x, lengths, y = textTensor(torch.LongTensor(range(32)), x_train, y_train)\n",
    "        x, y = Variable(x, volatile=True), Variable(y)\n",
    "        (x, y) = (x.cuda(device_id), y.cuda(device_id)) if use_cuda else (x, y)\n",
    "        output = clf(x, lengths)\n",
    "        output = output > 0.5\n",
    "        correct += (output.float() == y).sum().data[0]\n",
    "        total += y.size(0)\n",
    "    print('Accuracy of the network on the {} texts: {} %'.format(y_test.shape[0], 100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LATEST",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
