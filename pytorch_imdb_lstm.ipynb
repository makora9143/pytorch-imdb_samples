{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:05:38.347818",
     "start_time": "2017-06-20T14:05:36.342397+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "use_cuda = True\n",
    "device_id = 3\n",
    "from tensorflow.contrib.keras.python.keras.datasets.imdb import load_data, get_word_index\n",
    "\n",
    "max_features = 5000\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:05:38.357950",
     "start_time": "2017-06-20T14:05:38.349262+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:06:21.415679",
     "start_time": "2017-06-20T14:05:38.359172+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data(num_words=max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:06:21.421756",
     "start_time": "2017-06-20T14:06:21.417243+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad(tensor, length):\n",
    "    return torch.cat([tensor, tensor.new(length - tensor.size(0),*tensor.size()[1:]).zero_()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:06:21.452304",
     "start_time": "2017-06-20T14:06:21.422740+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sortedText(idx, xs, ys):\n",
    "    batch_xs = xs[idx]\n",
    "    batch_ys = ys[idx]\n",
    "    lengths = np.array([len(x) for x in batch_xs])\n",
    "    sort_idx = np.argsort(lengths)[::-1]\n",
    "    return batch_xs[sort_idx], lengths[sort_idx], batch_ys[sort_idx]\n",
    "\n",
    "\n",
    "def textTensor(idx, xs, ys):\n",
    "    batch_xs, lengths, batch_ys = sortedText(idx, xs, ys)\n",
    "    max_length = lengths[0]\n",
    "    return torch.cat([pad(torch.Tensor(x), max_length).view(max_length, 1)\n",
    "                      for x in batch_xs], 1).long(), list(lengths), torch.FloatTensor(batch_ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:06:21.480883",
     "start_time": "2017-06-20T14:06:21.453494+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IMDB_Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, n_layers=1):\n",
    "        super(IMDB_Classifier, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, word_input, input_length, hidden=None):\n",
    "        word_embedded = self.embedding(word_input)\n",
    "#         output = self.dropout(word_embedded)\n",
    "        output = word_embedded\n",
    "        output = pack_padded_sequence(output, input_length)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = get_last_step_tensor(output, input_length)\n",
    "        output = F.sigmoid(self.dense(output))\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    \n",
    "    def initHidden(self):\n",
    "        hidden = Variable(torch.zeros(1, self.batch_size, self.hidden_size))\n",
    "        cell = Variable(torch.zeros(1, self.batch_size, self.hidden_size))\n",
    "        return (hidden.cuda(device_id), cell.cuda(device_id)) if use_cuda else (hidden, cell) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:06:21.503015",
     "start_time": "2017-06-20T14:06:21.482416+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_last_step_indices(lengths):\n",
    "    n_lengths = len(lengths)\n",
    "    rev_lengths = lengths[::-1]\n",
    "    rev_lengths_sum = torch.LongTensor(rev_lengths).cumsum(0)\n",
    "    return torch.LongTensor([(n_lengths - i - 1) * length + rev_lengths_sum[i] - 1\n",
    "                         for i, length in enumerate(rev_lengths)][::-1])\n",
    "\n",
    "\n",
    "def get_last_step_tensor(packed_sequence, lengths):\n",
    "    indices = Variable(torch.LongTensor(get_last_step_indices(lengths)))\n",
    "    if packed_sequence.data.data.is_cuda:\n",
    "        indices = indices.cuda(packed_sequence.data.data.get_device())\n",
    "    last_step = packed_sequence.data.index_select(0, indices)\n",
    "    return last_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-20T05:05:36.105Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    idx, y = iter(train_loader).next()\n",
    "    x, lengths, y = textTensor(idx, x_train, y_train)\n",
    "    x, y = Variable(x), Variable(y)\n",
    "    print('input_batches', x.size()) \n",
    "    model = IMDB_Classifier(max_features, 2, 32)\n",
    "    model = model.cuda() if use_cuda else model\n",
    "    (x, y) = (x.cuda(), y.cuda()) if use_cuda else (x, y)\n",
    "    output = model(x, lengths)\n",
    "    print('output_batches', output.size()) \n",
    "    cretrion = nn.BCELoss()\n",
    "\n",
    "    print(cretrion(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-06-20T05:05:36.109Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 10, batch_loss: 0.69545943141\n",
      "batch: 20, batch_loss: 0.691866585612\n",
      "batch: 30, batch_loss: 0.690033572912\n",
      "batch: 40, batch_loss: 0.688602542877\n",
      "batch: 50, batch_loss: 0.688659090996\n",
      "batch: 60, batch_loss: 0.687320863207\n",
      "batch: 70, batch_loss: 0.68498005867\n",
      "batch: 80, batch_loss: 0.683520531654\n",
      "batch: 90, batch_loss: 0.68325273527\n",
      "batch: 100, batch_loss: 0.679330698848\n",
      "batch: 110, batch_loss: 0.678382878412\n",
      "batch: 120, batch_loss: 0.672522056599\n",
      "batch: 130, batch_loss: 0.67177152221\n",
      "batch: 140, batch_loss: 0.667980640275\n",
      "batch: 150, batch_loss: 0.66621500055\n",
      "batch: 160, batch_loss: 0.665801773965\n",
      "batch: 170, batch_loss: 0.664297933789\n",
      "batch: 180, batch_loss: 0.662891145547\n",
      "batch: 190, batch_loss: 0.660225103717\n",
      "batch: 200, batch_loss: 0.654279608577\n",
      "batch: 210, batch_loss: 0.651508088481\n",
      "batch: 220, batch_loss: 0.649304654246\n",
      "batch: 230, batch_loss: 0.647736446106\n",
      "batch: 240, batch_loss: 0.645605652158\n",
      "batch: 250, batch_loss: 0.642742213368\n",
      "batch: 260, batch_loss: 0.641271293278\n",
      "batch: 270, batch_loss: 0.640277818839\n",
      "batch: 280, batch_loss: 0.639030138935\n",
      "batch: 290, batch_loss: 0.636933143899\n",
      "batch: 300, batch_loss: 0.635473065873\n",
      "batch: 310, batch_loss: 0.633300299125\n",
      "batch: 320, batch_loss: 0.630199204944\n",
      "batch: 330, batch_loss: 0.628416026993\n",
      "batch: 340, batch_loss: 0.626825142871\n",
      "batch: 350, batch_loss: 0.62423387519\n",
      "batch: 360, batch_loss: 0.62293313601\n",
      "batch: 370, batch_loss: 0.622251633293\n",
      "batch: 380, batch_loss: 0.621796567895\n",
      "batch: 390, batch_loss: 0.61990033113\n",
      "batch: 400, batch_loss: 0.617315956727\n",
      "batch: 410, batch_loss: 0.616538981039\n",
      "batch: 420, batch_loss: 0.61516204228\n",
      "batch: 430, batch_loss: 0.614706015448\n",
      "batch: 440, batch_loss: 0.613778257776\n",
      "batch: 450, batch_loss: 0.61277222534\n",
      "batch: 460, batch_loss: 0.611048684755\n",
      "batch: 470, batch_loss: 0.608614265919\n",
      "batch: 480, batch_loss: 0.607366821294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = IMDB_Classifier(max_features, 128, batch_size)\n",
    "clf = clf.cuda(device_id) if use_cuda else clf\n",
    "optimizer = optim.Adam(clf.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, 101):\n",
    "    losses = 0\n",
    "    indices = np.random.permutation(np.array(range(25000)))\n",
    "    for i in range(1, indices.shape[0] / 32 + 1):\n",
    "        x, lengths, y = textTensor(indices[(i-1)*32:i*32], x_train, y_train)\n",
    "        x, y = Variable(x), Variable(y)\n",
    "\n",
    "        (x, y) = (x.cuda(device_id), y.cuda(device_id)) if use_cuda else (x, y)\n",
    "\n",
    "        output = clf(x, lengths)\n",
    "        loss = criterion(output, y)\n",
    "        losses += loss.data[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"batch: {}, batch_loss: {}\".format(i, losses / i))\n",
    "\n",
    "    print(\"Epoch: {}, time: {}, loss: {}\".format(epoch, timeSince(start, float(epoch) / epochs), losses/(i)))\n",
    "\n",
    "\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(250):\n",
    "        x, lengths, y = textTensor(range(25000)[i*100:(i+1)*100], x_train, y_train)\n",
    "        #x, lengths, y = textTensor(torch.LongTensor(range(32)), x_train, y_train)\n",
    "        x, y = Variable(x, volatile=True), Variable(y)\n",
    "        (x, y) = (x.cuda(device_id), y.cuda(device_id)) if use_cuda else (x, y)\n",
    "        output = clf(x, lengths)\n",
    "        output = output > 0.5\n",
    "        correct += (output.float() == y).sum().data[0]\n",
    "        total += y.size(0)\n",
    "    print('Accuracy of the network on the {} texts: {} %'.format(y_test.shape[0], 100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LATEST",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
