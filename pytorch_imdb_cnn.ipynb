{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:50:51.512798",
     "start_time": "2017-06-20T14:50:49.213107+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "use_cuda = True\n",
    "device_id = 3\n",
    "from tensorflow.contrib.keras.python.keras.datasets.imdb import load_data, get_word_index\n",
    "\n",
    "max_features = 5000\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:50:51.522613",
     "start_time": "2017-06-20T14:50:51.514125+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:36.621985",
     "start_time": "2017-06-20T14:50:51.524025+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data(num_words=max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:36.629066",
     "start_time": "2017-06-20T14:51:36.624064+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pad(tensor, length):\n",
    "    return torch.cat([tensor, tensor.new(length - tensor.size(0),*tensor.size()[1:]).zero_()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:36.682528",
     "start_time": "2017-06-20T14:51:36.630347+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sortedText(idx, xs, ys):\n",
    "    batch_xs = xs[idx]\n",
    "    batch_ys = ys[idx]\n",
    "    lengths = np.array([len(x) for x in batch_xs])\n",
    "    sort_idx = np.argsort(lengths)[::-1]\n",
    "    return batch_xs[sort_idx], lengths[sort_idx], batch_ys[sort_idx]\n",
    "\n",
    "\n",
    "def textTensor(idx, xs, ys):\n",
    "    batch_xs, lengths, batch_ys = sortedText(idx, xs, ys)\n",
    "    max_length = lengths[0]\n",
    "    return torch.cat([pad(torch.Tensor(x), max_length).view(max_length, 1)\n",
    "                      for x in batch_xs], 1).long(), list(lengths), torch.FloatTensor(batch_ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:53:25.539383",
     "start_time": "2017-06-20T14:53:25.510529+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IMDB_Classifier(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, filters, hidden_size):\n",
    "        super(IMDB_Classifier, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.filters = filters\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv = nn.Conv1d(embedding_size, filters, 3, stride=1, padding=0)\n",
    "        self.dense1 = nn.Linear(filters, hidden_size)\n",
    "        self.dense2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, word_input):\n",
    "        word_embedded = self.embedding(word_input)\n",
    "        output = self.dropout(word_embedded)\n",
    "        output = output.transpose(0, 1).transpose(1,2)\n",
    "        output = F.relu(self.conv(output))\n",
    "        output = torch.max(output, 2)[0].squeeze()\n",
    "        output = F.relu(self.dropout(self.dense1(output)))\n",
    "        output = F.sigmoid(self.dense2(output))\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:56:18.377728",
     "start_time": "2017-06-20T14:55:16.230326+09:00"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 10, batch_loss: 0.795276343822\n",
      "batch: 20, batch_loss: 0.751570284367\n",
      "batch: 30, batch_loss: 0.739358232419\n",
      "batch: 40, batch_loss: 0.729999986291\n",
      "batch: 50, batch_loss: 0.722238819599\n",
      "batch: 60, batch_loss: 0.719582094749\n",
      "batch: 70, batch_loss: 0.718231364659\n",
      "batch: 80, batch_loss: 0.715972481668\n",
      "batch: 90, batch_loss: 0.713740558757\n",
      "batch: 100, batch_loss: 0.711170747876\n",
      "batch: 110, batch_loss: 0.709835349972\n",
      "batch: 120, batch_loss: 0.708382978539\n",
      "batch: 130, batch_loss: 0.706178793999\n",
      "batch: 140, batch_loss: 0.705328278031\n",
      "batch: 150, batch_loss: 0.704142908255\n",
      "batch: 160, batch_loss: 0.702794122323\n",
      "batch: 170, batch_loss: 0.700931138501\n",
      "batch: 180, batch_loss: 0.700097064177\n",
      "batch: 190, batch_loss: 0.699008051032\n",
      "batch: 200, batch_loss: 0.697991194725\n",
      "batch: 210, batch_loss: 0.69692274474\n",
      "batch: 220, batch_loss: 0.695957202532\n",
      "batch: 230, batch_loss: 0.694566332257\n",
      "batch: 240, batch_loss: 0.693408409506\n",
      "batch: 250, batch_loss: 0.691588876247\n",
      "batch: 260, batch_loss: 0.68936003309\n",
      "batch: 270, batch_loss: 0.68733943193\n",
      "batch: 280, batch_loss: 0.684810644601\n",
      "batch: 290, batch_loss: 0.682652233592\n",
      "batch: 300, batch_loss: 0.680917338729\n",
      "batch: 310, batch_loss: 0.678063593757\n",
      "batch: 320, batch_loss: 0.676510066167\n",
      "batch: 330, batch_loss: 0.672808603897\n",
      "batch: 340, batch_loss: 0.670139773015\n",
      "batch: 350, batch_loss: 0.666286618539\n",
      "batch: 360, batch_loss: 0.663492608484\n",
      "batch: 370, batch_loss: 0.659260360373\n",
      "batch: 380, batch_loss: 0.655421787971\n",
      "batch: 390, batch_loss: 0.65243384777\n",
      "batch: 400, batch_loss: 0.650135873258\n",
      "batch: 410, batch_loss: 0.646271314054\n",
      "batch: 420, batch_loss: 0.643546869783\n",
      "batch: 430, batch_loss: 0.640671806141\n",
      "batch: 440, batch_loss: 0.637734960291\n",
      "batch: 450, batch_loss: 0.635179154674\n",
      "batch: 460, batch_loss: 0.631239135175\n",
      "batch: 470, batch_loss: 0.630087643291\n",
      "batch: 480, batch_loss: 0.628533007825\n",
      "batch: 490, batch_loss: 0.625856869622\n",
      "batch: 500, batch_loss: 0.622058205366\n",
      "batch: 510, batch_loss: 0.61942275523\n",
      "batch: 520, batch_loss: 0.616991758576\n",
      "batch: 530, batch_loss: 0.613921938921\n",
      "batch: 540, batch_loss: 0.610262085497\n",
      "batch: 550, batch_loss: 0.606951402534\n",
      "batch: 560, batch_loss: 0.60467729345\n",
      "batch: 570, batch_loss: 0.603264373332\n",
      "batch: 580, batch_loss: 0.601121626075\n",
      "batch: 590, batch_loss: 0.599848818122\n",
      "batch: 600, batch_loss: 0.598164220105\n",
      "batch: 610, batch_loss: 0.595689807857\n",
      "batch: 620, batch_loss: 0.593024810668\n",
      "batch: 630, batch_loss: 0.59000683143\n",
      "batch: 640, batch_loss: 0.587047515018\n",
      "batch: 650, batch_loss: 0.584653211557\n",
      "batch: 660, batch_loss: 0.582779865373\n",
      "batch: 670, batch_loss: 0.581490067181\n",
      "batch: 680, batch_loss: 0.580126497281\n",
      "batch: 690, batch_loss: 0.578301071905\n",
      "batch: 700, batch_loss: 0.576535942342\n",
      "batch: 710, batch_loss: 0.573635450719\n",
      "batch: 720, batch_loss: 0.570543890819\n",
      "batch: 730, batch_loss: 0.568029242142\n",
      "batch: 740, batch_loss: 0.566644123519\n",
      "batch: 750, batch_loss: 0.566247452736\n",
      "batch: 760, batch_loss: 0.564591555297\n",
      "batch: 770, batch_loss: 0.563272629311\n",
      "batch: 780, batch_loss: 0.561221754895\n",
      "Epoch: 1, time: 0m 12s (- 2m 51s), loss: 0.561074244304\n",
      "Accuracy of the network on the 25000 texts: 82.46 %\n",
      "batch: 10, batch_loss: 0.325496992469\n",
      "batch: 20, batch_loss: 0.369613447785\n",
      "batch: 30, batch_loss: 0.365737091502\n",
      "batch: 40, batch_loss: 0.370524921268\n",
      "batch: 50, batch_loss: 0.372921941876\n",
      "batch: 60, batch_loss: 0.37477962176\n",
      "batch: 70, batch_loss: 0.367587077618\n",
      "batch: 80, batch_loss: 0.374090996385\n",
      "batch: 90, batch_loss: 0.375751467877\n",
      "batch: 100, batch_loss: 0.377986378074\n",
      "batch: 110, batch_loss: 0.376084412228\n",
      "batch: 120, batch_loss: 0.376119036973\n",
      "batch: 130, batch_loss: 0.376872403117\n",
      "batch: 140, batch_loss: 0.376691447837\n",
      "batch: 150, batch_loss: 0.37357749174\n",
      "batch: 160, batch_loss: 0.375480508339\n",
      "batch: 170, batch_loss: 0.373223290812\n",
      "batch: 180, batch_loss: 0.370551276124\n",
      "batch: 190, batch_loss: 0.372325514571\n",
      "batch: 200, batch_loss: 0.378428572044\n",
      "batch: 210, batch_loss: 0.381485361499\n",
      "batch: 220, batch_loss: 0.385136092996\n",
      "batch: 230, batch_loss: 0.387202182736\n",
      "batch: 240, batch_loss: 0.385412464043\n",
      "batch: 250, batch_loss: 0.384035745382\n",
      "batch: 260, batch_loss: 0.385704482977\n",
      "batch: 270, batch_loss: 0.383630767796\n",
      "batch: 280, batch_loss: 0.381750044759\n",
      "batch: 290, batch_loss: 0.381781962103\n",
      "batch: 300, batch_loss: 0.380597795943\n",
      "batch: 310, batch_loss: 0.380332315449\n",
      "batch: 320, batch_loss: 0.381603197847\n",
      "batch: 330, batch_loss: 0.381009606791\n",
      "batch: 340, batch_loss: 0.379337466552\n",
      "batch: 350, batch_loss: 0.380118216063\n",
      "batch: 360, batch_loss: 0.379407043962\n",
      "batch: 370, batch_loss: 0.377107316497\n",
      "batch: 380, batch_loss: 0.376793555406\n",
      "batch: 390, batch_loss: 0.377900698666\n",
      "batch: 400, batch_loss: 0.37747917939\n",
      "batch: 410, batch_loss: 0.376562214879\n",
      "batch: 420, batch_loss: 0.375771555021\n",
      "batch: 430, batch_loss: 0.3744239515\n",
      "batch: 440, batch_loss: 0.372668976269\n",
      "batch: 450, batch_loss: 0.373501380351\n",
      "batch: 460, batch_loss: 0.373137035772\n",
      "batch: 470, batch_loss: 0.373330814915\n",
      "batch: 480, batch_loss: 0.37348739809\n",
      "batch: 490, batch_loss: 0.373813053053\n",
      "batch: 500, batch_loss: 0.37400161761\n",
      "batch: 510, batch_loss: 0.373829950831\n",
      "batch: 520, batch_loss: 0.373340705983\n",
      "batch: 530, batch_loss: 0.372428899638\n",
      "batch: 540, batch_loss: 0.372087394832\n",
      "batch: 550, batch_loss: 0.372028399896\n",
      "batch: 560, batch_loss: 0.372012766903\n",
      "batch: 570, batch_loss: 0.370655068651\n",
      "batch: 580, batch_loss: 0.36975983985\n",
      "batch: 590, batch_loss: 0.36945777937\n",
      "batch: 600, batch_loss: 0.368134749929\n",
      "batch: 610, batch_loss: 0.368221632403\n",
      "batch: 620, batch_loss: 0.368308470494\n",
      "batch: 630, batch_loss: 0.368625080467\n",
      "batch: 640, batch_loss: 0.368212515907\n",
      "batch: 650, batch_loss: 0.367312358549\n",
      "batch: 660, batch_loss: 0.368268556148\n",
      "batch: 670, batch_loss: 0.367175909499\n",
      "batch: 680, batch_loss: 0.367373699037\n",
      "batch: 690, batch_loss: 0.366898537676\n",
      "batch: 700, batch_loss: 0.368127659048\n",
      "batch: 710, batch_loss: 0.3682329368\n",
      "batch: 720, batch_loss: 0.368291367156\n",
      "batch: 730, batch_loss: 0.368457218658\n",
      "batch: 740, batch_loss: 0.368639052277\n",
      "batch: 750, batch_loss: 0.368857699056\n",
      "batch: 760, batch_loss: 0.36771409141\n",
      "batch: 770, batch_loss: 0.367658873019\n",
      "batch: 780, batch_loss: 0.367047505635\n",
      "Epoch: 2, time: 0m 26s (- 2m 54s), loss: 0.366853461299\n",
      "Accuracy of the network on the 25000 texts: 87.992 %\n",
      "batch: 10, batch_loss: 0.319400404394\n",
      "batch: 20, batch_loss: 0.322153372318\n",
      "batch: 30, batch_loss: 0.321288524568\n",
      "batch: 40, batch_loss: 0.317181069963\n",
      "batch: 50, batch_loss: 0.309513260275\n",
      "batch: 60, batch_loss: 0.298083136852\n",
      "batch: 70, batch_loss: 0.297540341424\n",
      "batch: 80, batch_loss: 0.301028822642\n",
      "batch: 90, batch_loss: 0.300667675916\n",
      "batch: 100, batch_loss: 0.295389825329\n",
      "batch: 110, batch_loss: 0.297896047682\n",
      "batch: 120, batch_loss: 0.298267665195\n",
      "batch: 130, batch_loss: 0.298232952161\n",
      "batch: 140, batch_loss: 0.295462796784\n",
      "batch: 150, batch_loss: 0.293644220382\n",
      "batch: 160, batch_loss: 0.292355519021\n",
      "batch: 170, batch_loss: 0.296140817728\n",
      "batch: 180, batch_loss: 0.297424687487\n",
      "batch: 190, batch_loss: 0.297085201701\n",
      "batch: 200, batch_loss: 0.295694151334\n",
      "batch: 210, batch_loss: 0.295541237046\n",
      "batch: 220, batch_loss: 0.297443126244\n",
      "batch: 230, batch_loss: 0.298504459113\n",
      "batch: 240, batch_loss: 0.299332939057\n",
      "batch: 250, batch_loss: 0.296722837895\n",
      "batch: 260, batch_loss: 0.296074491023\n",
      "batch: 270, batch_loss: 0.299628604314\n",
      "batch: 280, batch_loss: 0.300104642633\n",
      "batch: 290, batch_loss: 0.3016241413\n",
      "batch: 300, batch_loss: 0.301273570731\n",
      "batch: 310, batch_loss: 0.301016275849\n",
      "batch: 320, batch_loss: 0.299323729216\n",
      "batch: 330, batch_loss: 0.299177534269\n",
      "batch: 340, batch_loss: 0.297634758165\n",
      "batch: 350, batch_loss: 0.300038605524\n",
      "batch: 360, batch_loss: 0.302063859399\n",
      "batch: 370, batch_loss: 0.302354087117\n",
      "batch: 380, batch_loss: 0.302196588367\n",
      "batch: 390, batch_loss: 0.301781061865\n",
      "batch: 400, batch_loss: 0.302646333296\n",
      "batch: 410, batch_loss: 0.302596877025\n",
      "batch: 420, batch_loss: 0.302795056981\n",
      "batch: 430, batch_loss: 0.302400250508\n",
      "batch: 440, batch_loss: 0.302196161567\n",
      "batch: 450, batch_loss: 0.303167286432\n",
      "batch: 460, batch_loss: 0.303211711979\n",
      "batch: 470, batch_loss: 0.302105703839\n",
      "batch: 480, batch_loss: 0.302042628468\n",
      "batch: 490, batch_loss: 0.301404662111\n",
      "batch: 500, batch_loss: 0.301271254554\n",
      "batch: 510, batch_loss: 0.300788082051\n",
      "batch: 520, batch_loss: 0.300005202726\n",
      "batch: 530, batch_loss: 0.299960344341\n",
      "batch: 540, batch_loss: 0.300103667585\n",
      "batch: 550, batch_loss: 0.300461817722\n",
      "batch: 560, batch_loss: 0.30012267063\n",
      "batch: 570, batch_loss: 0.300909257393\n",
      "batch: 580, batch_loss: 0.300280216606\n",
      "batch: 590, batch_loss: 0.301467609671\n",
      "batch: 600, batch_loss: 0.300591463136\n",
      "batch: 610, batch_loss: 0.302256242308\n",
      "batch: 620, batch_loss: 0.302276878143\n",
      "batch: 630, batch_loss: 0.300982056806\n",
      "batch: 640, batch_loss: 0.300492554088\n",
      "batch: 650, batch_loss: 0.299939034352\n",
      "batch: 660, batch_loss: 0.300842124856\n",
      "batch: 670, batch_loss: 0.301786741859\n",
      "batch: 680, batch_loss: 0.301789300955\n",
      "batch: 690, batch_loss: 0.302647227502\n",
      "batch: 700, batch_loss: 0.302048804057\n",
      "batch: 710, batch_loss: 0.301631312009\n",
      "batch: 720, batch_loss: 0.302108283506\n",
      "batch: 730, batch_loss: 0.302369537827\n",
      "batch: 740, batch_loss: 0.301953450429\n",
      "batch: 750, batch_loss: 0.30222592785\n",
      "batch: 760, batch_loss: 0.302131727632\n",
      "batch: 770, batch_loss: 0.302159591967\n",
      "batch: 780, batch_loss: 0.302680141517\n",
      "Epoch: 3, time: 0m 41s (- 2m 45s), loss: 0.302684616894\n",
      "Accuracy of the network on the 25000 texts: 88.348 %\n",
      "batch: 10, batch_loss: 0.265154896677\n",
      "batch: 20, batch_loss: 0.255606646091\n",
      "batch: 30, batch_loss: 0.241012216111\n",
      "batch: 40, batch_loss: 0.247467750683\n",
      "batch: 50, batch_loss: 0.24551715076\n",
      "batch: 60, batch_loss: 0.247222781926\n",
      "batch: 70, batch_loss: 0.251508022419\n",
      "batch: 80, batch_loss: 0.250739065558\n",
      "batch: 90, batch_loss: 0.254842969775\n",
      "batch: 100, batch_loss: 0.257596238703\n",
      "batch: 110, batch_loss: 0.255031440068\n",
      "batch: 120, batch_loss: 0.253054735685\n",
      "batch: 130, batch_loss: 0.251954298065\n",
      "batch: 140, batch_loss: 0.252157571646\n",
      "batch: 150, batch_loss: 0.248242258777\n",
      "batch: 160, batch_loss: 0.248176122876\n",
      "batch: 170, batch_loss: 0.252743634362\n",
      "batch: 180, batch_loss: 0.253505576857\n",
      "batch: 190, batch_loss: 0.253025687094\n",
      "batch: 200, batch_loss: 0.252342511937\n",
      "batch: 210, batch_loss: 0.251141162926\n",
      "batch: 220, batch_loss: 0.251774494892\n",
      "batch: 230, batch_loss: 0.25180589615\n",
      "batch: 240, batch_loss: 0.253405922341\n",
      "batch: 250, batch_loss: 0.252790700942\n",
      "batch: 260, batch_loss: 0.253801851061\n",
      "batch: 270, batch_loss: 0.252676224129\n",
      "batch: 280, batch_loss: 0.251048439555\n",
      "batch: 290, batch_loss: 0.251630171543\n",
      "batch: 300, batch_loss: 0.250874768371\n",
      "batch: 310, batch_loss: 0.251071442111\n",
      "batch: 320, batch_loss: 0.252015693579\n",
      "batch: 330, batch_loss: 0.252359601765\n",
      "batch: 340, batch_loss: 0.253618664864\n",
      "batch: 350, batch_loss: 0.253473141747\n",
      "batch: 360, batch_loss: 0.254542056285\n",
      "batch: 370, batch_loss: 0.254363745632\n",
      "batch: 380, batch_loss: 0.254392008778\n",
      "batch: 390, batch_loss: 0.255016580893\n",
      "batch: 400, batch_loss: 0.255360050742\n",
      "batch: 410, batch_loss: 0.254643532706\n",
      "batch: 420, batch_loss: 0.254006532172\n",
      "batch: 430, batch_loss: 0.252345303377\n",
      "batch: 440, batch_loss: 0.252961902185\n",
      "batch: 450, batch_loss: 0.253369745149\n",
      "batch: 460, batch_loss: 0.254930188896\n",
      "batch: 470, batch_loss: 0.254798573351\n",
      "batch: 480, batch_loss: 0.253982691001\n",
      "batch: 490, batch_loss: 0.255568071166\n",
      "batch: 500, batch_loss: 0.255568877324\n",
      "batch: 510, batch_loss: 0.255928078454\n",
      "batch: 520, batch_loss: 0.25598019979\n",
      "batch: 530, batch_loss: 0.255140042572\n",
      "batch: 540, batch_loss: 0.254360215352\n",
      "batch: 550, batch_loss: 0.255034390566\n",
      "batch: 560, batch_loss: 0.254834636181\n",
      "batch: 570, batch_loss: 0.25593667897\n",
      "batch: 580, batch_loss: 0.255891066931\n",
      "batch: 590, batch_loss: 0.255577204831\n",
      "batch: 600, batch_loss: 0.25432096829\n",
      "batch: 610, batch_loss: 0.254369416247\n",
      "batch: 620, batch_loss: 0.254581821361\n",
      "batch: 630, batch_loss: 0.254576536564\n",
      "batch: 640, batch_loss: 0.254945374245\n",
      "batch: 650, batch_loss: 0.254733451295\n",
      "batch: 660, batch_loss: 0.255133305434\n",
      "batch: 670, batch_loss: 0.255809794845\n",
      "batch: 680, batch_loss: 0.255776890137\n",
      "batch: 690, batch_loss: 0.255608976902\n",
      "batch: 700, batch_loss: 0.25564457589\n",
      "batch: 710, batch_loss: 0.255573907012\n",
      "batch: 720, batch_loss: 0.25637132511\n",
      "batch: 730, batch_loss: 0.256087342762\n",
      "batch: 740, batch_loss: 0.25592335377\n",
      "batch: 750, batch_loss: 0.25614486295\n",
      "batch: 760, batch_loss: 0.256236652108\n",
      "batch: 770, batch_loss: 0.255894146724\n",
      "batch: 780, batch_loss: 0.256150612741\n",
      "Epoch: 4, time: 0m 55s (- 2m 33s), loss: 0.25616246688\n",
      "Accuracy of the network on the 25000 texts: 92.172 %\n",
      "batch: 10, batch_loss: 0.243857558072\n",
      "batch: 20, batch_loss: 0.231676515937\n",
      "batch: 30, batch_loss: 0.215640002489\n",
      "batch: 40, batch_loss: 0.206749040913\n",
      "batch: 50, batch_loss: 0.205603298768\n",
      "batch: 60, batch_loss: 0.204271708491\n",
      "batch: 70, batch_loss: 0.197236504033\n",
      "batch: 80, batch_loss: 0.199562475039\n",
      "batch: 90, batch_loss: 0.196815372672\n",
      "batch: 100, batch_loss: 0.202559845001\n",
      "batch: 110, batch_loss: 0.204653592746\n",
      "batch: 120, batch_loss: 0.209782190683\n",
      "batch: 130, batch_loss: 0.210250030458\n",
      "batch: 140, batch_loss: 0.209657889285\n",
      "batch: 150, batch_loss: 0.211872955163\n",
      "batch: 160, batch_loss: 0.212607470993\n",
      "batch: 170, batch_loss: 0.211922088222\n",
      "batch: 180, batch_loss: 0.213651123602\n",
      "batch: 190, batch_loss: 0.211320885232\n",
      "batch: 200, batch_loss: 0.212214943133\n",
      "batch: 210, batch_loss: 0.211637427161\n",
      "batch: 220, batch_loss: 0.213243830187\n",
      "batch: 230, batch_loss: 0.212758854598\n",
      "batch: 240, batch_loss: 0.213993365178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c051a6413530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/src/pyenv/versions/latest_mod/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/src/pyenv/versions/latest_mod/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_was_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/src/pyenv/versions/latest_mod/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = IMDB_Classifier(max_features, 50, 250, 250)\n",
    "clf = clf.cuda(device_id) if use_cuda else clf\n",
    "optimizer = optim.Adam(clf.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, 101):\n",
    "    losses = 0\n",
    "    indices = np.random.permutation(np.array(range(25000)))\n",
    "    for i in range(1, indices.shape[0] / 32 + 1):\n",
    "        x, lengths, y = textTensor(indices[(i-1)*32:i*32], x_train, y_train)\n",
    "        x, y = Variable(x), Variable(y)\n",
    "\n",
    "        (x, y) = (x.cuda(device_id), y.cuda(device_id)) if use_cuda else (x, y)\n",
    "\n",
    "        output = clf(x)\n",
    "        loss = criterion(output, y)\n",
    "        losses += loss.data[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"batch: {}, batch_loss: {}\".format(i, losses / i))\n",
    "\n",
    "    print(\"Epoch: {}, time: {}, loss: {}\".format(epoch, timeSince(start, float(epoch) / epochs), losses/(i)))\n",
    "\n",
    "\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(250):\n",
    "        x, lengths, y = textTensor(range(25000)[i*100:(i+1)*100], x_train, y_train)\n",
    "        #x, lengths, y = textTensor(torch.LongTensor(range(32)), x_train, y_train)\n",
    "        x, y = Variable(x, volatile=True), Variable(y)\n",
    "        (x, y) = (x.cuda(device_id), y.cuda(device_id)) if use_cuda else (x, y)\n",
    "        output = clf(x)\n",
    "        output = output > 0.5\n",
    "        correct += (output.float() == y).sum().data[0]\n",
    "        total += y.size(0)\n",
    "    print('Accuracy of the network on the {} texts: {} %'.format(y_test.shape[0], 100. * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LATEST",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
